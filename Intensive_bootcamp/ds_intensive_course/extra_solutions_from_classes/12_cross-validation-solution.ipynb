{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from pandas import DataFrame\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score,KFold,StratifiedKFold,LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "You will use a logistic regression model as a baseline to apply the cross-validation techniques. Initialize the logistic regression model with the parameters provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "logit = LogisticRegression(max_iter=200, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross-Validation\n",
    "\n",
    "Implement K-Fold cross-validation with 5 splits and ensure that the dataset is shuffled before splitting. Calculate and output the cross-validation scores and the average score. Use the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold CV scores: [1.0, 1.0, 0.93, 0.97, 0.97]\n",
      "Average K-Fold CV score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# K-Fold Cross-Validation\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "logit_kfold_scores = cross_val_score(logit, X, y, cv=kf)\n",
    "\n",
    "print(f\"K-Fold CV scores: {[round(score,2) for score in logit_kfold_scores]}\")\n",
    "print(f\"Average K-Fold CV score: {logit_kfold_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold Cross-Validation\n",
    "\n",
    "The Iris dataset is balanced but in practice, datasets can often be imbalanced. Stratified K-Fold cross-validation is a variation of K-Fold that returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set. Implement Stratified K-Fold CV and explain why it might be preferred over regular K-Fold for imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified K-Fold CV scores: [1.0, 0.97, 0.93, 1.0, 0.93]\n",
      "Average Stratified K-Fold CV score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-Fold Cross-Validation\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "logit_strat_scores = cross_val_score(logit, X, y, cv=skf)\n",
    "\n",
    "print(f\"Stratified K-Fold CV scores: {[round(score,2) for score in logit_strat_scores]}\")\n",
    "print(f\"Average Stratified K-Fold CV score: {logit_strat_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Leave-One-Out Cross-Validation\n",
    "\n",
    "Leave-One-Out (LOO) is a cross-validation technique that can provide a robust estimate of model performance but can be computationally expensive, especially for large datasets. Implement LOO CV and discuss the trade-offs associated with using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave-One-Out CV scores: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Average Leave-One-Out CV score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Leave-One-Out Cross-Validation\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "logit_loo_scores = cross_val_score(logit, X, y, cv=loo)\n",
    "\n",
    "print(f\"Leave-One-Out CV scores: {[round(score,2) for score in logit_loo_scores]}\")\n",
    "print(f\"Average Leave-One-Out CV score: {logit_loo_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation with the Random Forest Classifier\n",
    "\n",
    "Now, let's try a different classifier. Use a RandomForestClassifier and perform the same three cross-validation techniques as before. Discuss the differences in the cross-validation scores between the logistic regression and the random forest classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest K-Fold CV scores: [1.0, 0.97, 0.93, 0.93, 0.97]\n",
      "Average Random Forest K-Fold CV score: 0.96\n",
      "Stratified K-Fold CV scores: [0.97, 0.97, 0.93, 0.97, 0.9]\n",
      "Average Stratified K-Fold CV score: 0.95\n",
      "Leave-One-Out CV scores: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Average Leave-One-Out CV score: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation with RF classifier\n",
    "\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "rf_kfold_scores = cross_val_score(rf, X, y, cv=kf)\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "rf_strat_scores = cross_val_score(rf,X,y,cv=skf)\n",
    "\n",
    "# Leave-One-Out Cross-Validation\n",
    "rf_loo_scores = cross_val_score(rf, X, y, cv=loo)\n",
    "\n",
    "print(f\"Random Forest K-Fold CV scores: {[round(score,2) for score in rf_kfold_scores]}\")\n",
    "print(f\"Average Random Forest K-Fold CV score: {rf_kfold_scores.mean():.2f}\")\n",
    "print(f\"Stratified K-Fold CV scores: {[round(score,2) for score in rf_strat_scores]}\")\n",
    "print(f\"Average Stratified K-Fold CV score: {rf_strat_scores.mean():.2f}\")\n",
    "print(f\"Leave-One-Out CV scores: {[round(score,2) for score in rf_loo_scores]}\")\n",
    "print(f\"Average Leave-One-Out CV score: {rf_loo_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the performances of the logistic regression with the Random Forest classifier, we find that the logistic regression is slightly preferable to the RF classifier although there is not much difference in performance. The reason is that our dataset is relatively small (150 observations and 4 features) and in such cases simpler models are preferred for their lower computational cost while having the same performances as more complex estimators such as the Random Forest Classifier. Even if we would have performed automatic parameter tuning *(we will see how to do this in the next batch)*, we shouldn't expect the Random Forest Classifier to have significantly higher performances.\n",
    "\n",
    "## Analysis\n",
    "\n",
    "Summarize the results from the previous tasks. Reflect on the average scores and the variability of the scores for each cross-validation technique. Discuss the implications of using each technique and the circumstances in which one might be preferred over the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K-Fold</th>\n",
       "      <th>Stratified K-Fold</th>\n",
       "      <th>Leave-One-Out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          K-Fold  Stratified K-Fold  Leave-One-Out\n",
       "Logistic Regression         0.97               0.97           0.97\n",
       "Random Forest Classifier    0.96               0.95           0.95"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf = DataFrame(\n",
    "    data = {\n",
    "        'K-Fold': [logit_kfold_scores.mean(),rf_kfold_scores.mean()],\n",
    "        'Stratified K-Fold': [logit_strat_scores.mean(),rf_strat_scores.mean()],\n",
    "        'Leave-One-Out': [logit_loo_scores.mean(),rf_loo_scores.mean()]\n",
    "    },\n",
    "    index = ['Logistic Regression', 'Random Forest Classifier']\n",
    ").round(2)\n",
    "perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris dataset contains the same number of observations for each species *(50 observations each)* which means that the dataset is very well balanced. From that, there shouldn't be significant difference between the K-Fold and Stratified K-Fold cross validation scores *(for both Logistic Regression and RF Classifier)* and the application of the Stratified K-Fold cross validation is not relevant in this case.\n",
    "\n",
    "The choice between applying **K-Fold** or **Leave-One-Out** depends on your business case. **If** your manager or client wants to have a performance estimate that is on average very close to the true unknown accuracy score but she doesn't care if your current estimate is likely to be very far from an estimate you would obtain with a different dataset **then** you should use the **Leave-One-Out** cross validation technique. Otherwise, **if** your manager or client doesn't care to have a performance estimate that is on average far to the true unknown accuracy score but she cares about the difference between your current estimate and an estimate you would obtain with a different dataset **then** you should use the **K-Fold** cross validation technique with K << N, N being the number of observations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
