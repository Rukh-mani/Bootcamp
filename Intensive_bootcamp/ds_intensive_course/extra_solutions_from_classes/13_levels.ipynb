{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1: Exploratory Data Analysis on the Iris Dataset\n",
    "### Data manipulation and visualization techniques.\n",
    "### Tasks:\n",
    "- Load the Iris dataset.\n",
    "- Perform basic checks (shape, data types, missing values).\n",
    "- Create visualizations (scatter plots, histograms) to understand the distribution of each feature and the relationships between them.\n",
    "- Summarize key findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "# Create a DataFrame\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "# Add the species column\n",
    "iris_df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "print(iris_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2: Basic Classification with Iris Dataset\n",
    "### Apply basic machine learning models.\n",
    "### Tasks:\n",
    "- Split the data into training and testing sets.\n",
    "- Apply a simple classifier like Logistic Regression.\n",
    "- Evaluate the model's performance using accuracy and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 3: Feature Engineering and PCA\n",
    "\n",
    "## Dimensionality reduction and feature engineering.\n",
    "\n",
    "Tasks:\n",
    "- Apply PCA to the Iris dataset and reduce its dimensions.\n",
    "- Visualize the data in the new feature space.\n",
    "- Use a classifier on the transformed data and compare its performance with the original data's classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 4: Advanced Model Application\n",
    "\n",
    "## Explore different models and their applications.\n",
    "\n",
    "## Tasks:\n",
    "- Use different classifiers (e.g., SVM, Decision Trees, K-Nearest Neighbors) on the Iris dataset.\n",
    "- Experiment with different hyperparameters for each model.\n",
    "- Compare the performance of these models using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 5: Experimenting with Different Scalers\n",
    "\n",
    "### Understand the impact of feature scaling.\n",
    "\n",
    "### Tasks:\n",
    "- Apply different scalers (StandardScaler, MinMaxScaler, RobustScaler) to the Iris dataset.\n",
    "- Use a consistent classifier to evaluate the impact of scaling on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 6: Regression with the Californie Housing Dataset\n",
    "### Regression problem.\n",
    "### Tasks:\n",
    "- Load and explore the California Housing dataset.\n",
    "- Apply regression models (Linear Regression, Ridge, Lasso).\n",
    "- Evaluate models using metrics like RMSE (Root Mean Square Error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "california_housing = fetch_california_housing()\n",
    "california_df = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
    "california_df['MedianHouseValue'] = california_housing.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 7: Hyperparameter Tuning\n",
    "### Fine-tune model parameters.\n",
    "### Tasks:\n",
    "- Use GridSearchCV or RandomizedSearchCV for hyperparameter tuning on a model of your choice.\n",
    "- Analyze the impact of hyperparameter tuning on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 8: Designing Pipelines for Different Models\n",
    "### Automating workflows.\n",
    "### Tasks:\n",
    "- Design a pipeline for a classification model on the Iris dataset (including preprocessing steps).\n",
    "- Create a pipeline for a regression model on the Boston Housing dataset.\n",
    "- Implement a pipeline for a more complex dataset/model of your choice, integrating advanced preprocessing and model selection steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
