{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-04 18:01:12.552022: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 132s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Convert class vectors to binary class matrices (one-hot encoding)\n",
    "y_train_one_hot = to_categorical(y_train, 10)\n",
    "y_test_one_hot = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained MobileNetV2 model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# Add custom layers on top of the pre-trained base\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # We have 10 classes in CIFAR-10\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 68s 41ms/step - loss: 1.9268 - accuracy: 0.3027 - val_loss: 1.8604 - val_accuracy: 0.3297\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 1.8283 - accuracy: 0.3364 - val_loss: 1.8300 - val_accuracy: 0.3352\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 73s 47ms/step - loss: 1.7909 - accuracy: 0.3476 - val_loss: 1.8096 - val_accuracy: 0.3442\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 1.7634 - accuracy: 0.3580 - val_loss: 1.8017 - val_accuracy: 0.3502\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 1.7409 - accuracy: 0.3669 - val_loss: 1.7949 - val_accuracy: 0.3496\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 1.7231 - accuracy: 0.3764 - val_loss: 1.7941 - val_accuracy: 0.3478\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.7066 - accuracy: 0.3803 - val_loss: 1.7926 - val_accuracy: 0.3569\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 1.6927 - accuracy: 0.3844 - val_loss: 1.7934 - val_accuracy: 0.3564\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 1.6804 - accuracy: 0.3895 - val_loss: 1.8015 - val_accuracy: 0.3553\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 1.6687 - accuracy: 0.3939 - val_loss: 1.7983 - val_accuracy: 0.3531\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    validation_data=(x_test, y_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 10s 33ms/step - loss: 1.7983 - accuracy: 0.3531\n",
      "Test accuracy: 0.353\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test_one_hot)\n",
    "print(f'Test accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 313s 191ms/step - loss: 2.1334 - accuracy: 0.3963 - val_loss: 2.0205 - val_accuracy: 0.2731\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 281s 179ms/step - loss: 1.3024 - accuracy: 0.5473 - val_loss: 2.0042 - val_accuracy: 0.3177\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 273s 175ms/step - loss: 1.2480 - accuracy: 0.5645 - val_loss: 1.6213 - val_accuracy: 0.4132\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 1.1143 - accuracy: 0.6178 - val_loss: 1.4299 - val_accuracy: 0.6063\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 312s 200ms/step - loss: 1.1227 - accuracy: 0.6122 - val_loss: 2.2343 - val_accuracy: 0.3235\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 305s 195ms/step - loss: 1.4612 - accuracy: 0.4888 - val_loss: 2.6166 - val_accuracy: 0.1462\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 309s 198ms/step - loss: 1.2948 - accuracy: 0.5367 - val_loss: 2.9566 - val_accuracy: 0.2089\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 309s 198ms/step - loss: 1.3411 - accuracy: 0.5305 - val_loss: 2.4033 - val_accuracy: 0.3902\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 316s 202ms/step - loss: 1.3231 - accuracy: 0.5335 - val_loss: 3.1195 - val_accuracy: 0.2001\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 260s 166ms/step - loss: 1.4288 - accuracy: 0.4887 - val_loss: 2.1191 - val_accuracy: 0.2426\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the entire model\n",
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# It's important to recompile the model after you make any changes to the\n",
    "# `trainable` attribute of any layer, so that your changes are taken into account\n",
    "model.compile(optimizer=Adam(lr=0.00001),  # Lower learning rate\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model again (this time fine-tuning the entire model)\n",
    "history_fine = model.fit(x_train, y_train_one_hot,\n",
    "                         batch_size=32,\n",
    "                         epochs=10,\n",
    "                         validation_data=(x_test, y_test_one_hot))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 10s 30ms/step - loss: 2.1191 - accuracy: 0.2426\n",
      "Fine-tuned test accuracy: 0.243\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model again\n",
    "loss_fine, accuracy_fine = model.evaluate(x_test, y_test_one_hot)\n",
    "print(f'Fine-tuned test accuracy: {accuracy_fine:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
